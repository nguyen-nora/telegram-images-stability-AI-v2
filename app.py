# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/blackestwhite/tele-sd/blob/master/app.ipynb

# Stable Diffusion + Telegram bot
[Github Repo](https://github.com/blackestwhite/tele-sd)

## Donations
Ethereum: `0xE76fc1CE4d3ffFEA12A5686618844408C327357b`

## steps
- create a telegram bot
- set the token on the code
- run all


## How to use
go to your bot on telegram send the Prompts separated by `__`, (two underlines).
before the separator will be the positive prompt, after that will be the negative prompt

## Mount Google Drive
"""

import os
from google.colab import drive

drivePath = '/content/drive'

if os.path.isdir(drivePath) == False:
    drive.mount(drivePath)

"""## Install Requirements"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install nest-asyncio
# %pip install transformers
# %pip install diffusers
# %pip install python-telegram-bot
# %pip install accelerate

"""## Import and Setup Bot + SD"""

from telegram import Update, Bot
from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes, MessageHandler, filters
import nest_asyncio
from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler
import torch
import asyncio

model_id = "runwayml/stable-diffusion-v1-5"
scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder="scheduler")



if os.path.isdir(f'{drivePath}/MyDrive/sd_1-5'):
    pipe = StableDiffusionPipeline.from_pretrained(f'{drivePath}/MyDrive/sd_1-5', torch_dtype=torch.float16, scheduler=scheduler)
else:
    pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16, scheduler=scheduler)
    pipe.save_pretrained(f'{drivePath}/MyDrive/sd_1-5')


pipe = pipe.to("cuda")
pipe.enable_attention_slicing() # to use less memory
pipe.safety_checker = lambda images, **kwargs: (images, False) # to disable NSFW filter

nest_asyncio.apply()
token = "Your Telegram Bot Token Here"

"""## Setup Handler for bot"""

default_steps = 20

async def generate(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
  text = update.message.text
  prompt = ''
  neg = ''
  if '__' in text:
    prompt = text.split("__")[0]
    neg = text.split("__")[1]
  else:
    prompt = text
  
  image = pipe(prompt, negative_prompt=neg, num_inference_steps=default_steps).images[0]
  image.save("./image.png")
  await update.message.reply_photo(photo="./image.png")

app = ApplicationBuilder().token(token).build()

app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, generate))

app.run_polling()